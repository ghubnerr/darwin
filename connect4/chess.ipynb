{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Stable-Baselines3 to train agents in the Connect Four environment using invalid action masking.\n",
    "\n",
    "For information about invalid action masking in PettingZoo, see https://pettingzoo.farama.org/api/aec/#action-masking\n",
    "For more information about invalid action masking in SB3, see https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html\n",
    "\n",
    "Author: Elliot (https://github.com/elliottower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pettingzoo.utils\n",
    "from pettingzoo.classic import connect_four_v3\n",
    "from sb3_contrib import MaskablePPO\n",
    "\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SB3ActionMaskWrapper(pettingzoo.utils.BaseWrapper):\n",
    "    \"\"\"Wrapper to allow PettingZoo environments to be used with SB3 illegal action masking.\"\"\"\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Gymnasium-like reset function which assigns obs/action spaces to be the same for each agent.\n",
    "\n",
    "        This is required as SB3 is designed for single-agent RL and doesn't expect obs/action spaces to be functions\n",
    "        \"\"\"\n",
    "        super().reset(seed, options)\n",
    "\n",
    "        # Strip the action mask out from the observation space\n",
    "        self.observation_space = super().observation_space(self.possible_agents[0])[\n",
    "            \"observation\"\n",
    "        ]\n",
    "        self.action_space = super().action_space(self.possible_agents[0])\n",
    "\n",
    "        # Return initial observation, info (PettingZoo AEC envs do not by default)\n",
    "        return self.observe(self.agent_selection), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Gymnasium-like step function, returning observation, reward, termination, truncation, info.\"\"\"\n",
    "        super().step(action)\n",
    "        return super().last()\n",
    "\n",
    "    def observe(self, agent):\n",
    "        \"\"\"Return only raw observation, removing action mask.\"\"\"\n",
    "        return super().observe(agent)[\"observation\"]\n",
    "\n",
    "    def action_mask(self):\n",
    "        \"\"\"Separate function used in order to access the action mask.\"\"\"\n",
    "        return super().observe(self.agent_selection)[\"action_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fn(env):\n",
    "    # Do whatever you'd like in this function to return the action mask\n",
    "    # for the current env. In this example, we assume the env has a\n",
    "    # helpful method we can rely on.\n",
    "    return env.action_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_action_mask(env_fn, steps=10_000, seed=0, **env_kwargs):\n",
    "    \"\"\"Train a single model to play as each agent in a zero-sum game environment using invalid action masking.\"\"\"\n",
    "    env = env_fn.env(**env_kwargs)\n",
    "\n",
    "    print(f\"Starting training on {str(env.metadata['name'])}.\")\n",
    "\n",
    "    # Custom wrapper to convert PettingZoo envs to work with SB3 action masking\n",
    "    env = SB3ActionMaskWrapper(env)\n",
    "\n",
    "    env.reset(seed=seed)  # Must call reset() in order to re-define the spaces\n",
    "\n",
    "    env = ActionMasker(env, mask_fn)  # Wrap to enable masking (SB3 function)\n",
    "    # MaskablePPO behaves the same as SB3's PPO unless the env is wrapped\n",
    "    # with ActionMasker. If the wrapper is detected, the masks are automatically\n",
    "    # retrieved and used when learning. Note that MaskablePPO does not accept\n",
    "    # a new action_mask_fn kwarg, as it did in an earlier draft.\n",
    "    model = MaskablePPO(MaskableActorCriticPolicy, env, verbose=1)\n",
    "    model.set_random_seed(seed)\n",
    "    model.learn(total_timesteps=steps)\n",
    "\n",
    "    model.save(f\"{env.unwrapped.metadata.get('name')}_{time.strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "    print(\"Model has been saved.\")\n",
    "\n",
    "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\\n\")\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "def eval_action_mask(env_fn, num_games=100, render_mode=None, **env_kwargs):\n",
    "    # Evaluate a trained agent vs a random agent\n",
    "    env = env_fn.env(render_mode=render_mode, **env_kwargs)\n",
    "\n",
    "    print(\n",
    "        f\"Starting evaluation vs a random agent. Trained agent will play as {env.possible_agents[1]}.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        latest_policy = max(\n",
    "            glob.glob(f\"{env.metadata['name']}*.zip\"), key=os.path.getctime\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"Policy not found.\")\n",
    "        exit(0)\n",
    "\n",
    "    print(f\"Using policy {latest_policy}\")\n",
    "    model = MaskablePPO.load(latest_policy)\n",
    "\n",
    "    scores = {agent: 0 for agent in env.possible_agents}\n",
    "    total_rewards = {agent: 0 for agent in env.possible_agents}\n",
    "    round_rewards = []\n",
    "\n",
    "    for i in range(num_games):\n",
    "        env.reset(seed=i)\n",
    "        env.action_space(env.possible_agents[0]).seed(i)\n",
    "\n",
    "        for agent in env.agent_iter():\n",
    "            obs, reward, termination, truncation, info = env.last()\n",
    "            sleep(0.3)\n",
    "\n",
    "            # Separate observation and action mask\n",
    "            observation, action_mask = obs.values()\n",
    "\n",
    "            if termination or truncation:\n",
    "                # If there is a winner, keep track, otherwise don't change the scores (tie)\n",
    "                if (\n",
    "                    env.rewards[env.possible_agents[0]]\n",
    "                    != env.rewards[env.possible_agents[1]]\n",
    "                ):\n",
    "                    winner = max(env.rewards, key=env.rewards.get)\n",
    "                    scores[winner] += env.rewards[\n",
    "                        winner\n",
    "                    ]  # only tracks the largest reward (winner of game)\n",
    "                # Also track negative and positive rewards (penalizes illegal moves)\n",
    "                for a in env.possible_agents:\n",
    "                    total_rewards[a] += env.rewards[a]\n",
    "                # List of rewards by round, for reference\n",
    "                round_rewards.append(env.rewards)\n",
    "                break\n",
    "            else:\n",
    "                if agent == env.possible_agents[0]:\n",
    "                    act = env.action_space(agent).sample(action_mask)\n",
    "                else:\n",
    "                    # Note: PettingZoo expects integer actions # TODO: change chess to cast actions to type int?\n",
    "                    act = int(\n",
    "                        model.predict(\n",
    "                            observation, action_masks=action_mask, deterministic=True\n",
    "                        )[0]\n",
    "                    )\n",
    "            env.step(act)\n",
    "    env.close()\n",
    "\n",
    "    # Avoid dividing by zero\n",
    "    if sum(scores.values()) == 0:\n",
    "        winrate = 0\n",
    "    else:\n",
    "        winrate = scores[env.possible_agents[1]] / sum(scores.values())\n",
    "    print(\"Rewards by round: \", round_rewards)\n",
    "    print(\"Total rewards (incl. negative rewards): \", total_rewards)\n",
    "    print(\"Winrate: \", winrate)\n",
    "    print(\"Final scores: \", scores)\n",
    "    return round_rewards, total_rewards, winrate, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import chess_v6\n",
    "from pettingzoo.classic import rps_v2\n",
    "from pettingzoo.classic import connect_four_v3\n",
    "\n",
    "env_fn = connect_four_v3\n",
    "\n",
    "env_kwargs = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on chess_v6.\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/dev/ai-guild/.venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 336      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | -0.0833     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034933783 |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | -3.85       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.148      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.104      |\n",
      "|    value_loss           | 0.00348     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | -0.118      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040534653 |\n",
      "|    clip_fraction        | 0.526       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.114      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.132      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.104      |\n",
      "|    value_loss           | 0.000698    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | -0.087      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040450685 |\n",
      "|    clip_fraction        | 0.527       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.151      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.143      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0942     |\n",
      "|    value_loss           | 0.00118     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 351        |\n",
      "|    ep_rew_mean          | -0.0714    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 245        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04589554 |\n",
      "|    clip_fraction        | 0.572      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.7       |\n",
      "|    explained_variance   | -1.22      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.141     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.117     |\n",
      "|    value_loss           | 0.000271   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | -0.0606     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048897058 |\n",
      "|    clip_fraction        | 0.589       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | -1.05       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.142      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.121      |\n",
      "|    value_loss           | 0.00014     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | -0.122      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050954208 |\n",
      "|    clip_fraction        | 0.59        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | -2.67       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.135      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.118      |\n",
      "|    value_loss           | 7.68e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | -0.125      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038625143 |\n",
      "|    clip_fraction        | 0.46        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | -0.0238     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0924     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0655     |\n",
      "|    value_loss           | 0.00101     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | -0.127      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049535535 |\n",
      "|    clip_fraction        | 0.526       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.00208     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0678     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.088      |\n",
      "|    value_loss           | 0.000407    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | -0.131      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049773738 |\n",
      "|    clip_fraction        | 0.527       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | -0.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.134      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0772     |\n",
      "|    value_loss           | 0.000785    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 338         |\n",
      "|    ep_rew_mean          | -0.121      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046369042 |\n",
      "|    clip_fraction        | 0.51        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | -0.00608    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.133      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0766     |\n",
      "|    value_loss           | 0.000441    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 335        |\n",
      "|    ep_rew_mean          | -0.123     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 227        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06326571 |\n",
      "|    clip_fraction        | 0.636      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.73      |\n",
      "|    explained_variance   | -0.105     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.14      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.122     |\n",
      "|    value_loss           | 5.35e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 337        |\n",
      "|    ep_rew_mean          | -0.127     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 227        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 117        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05020387 |\n",
      "|    clip_fraction        | 0.505      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.84      |\n",
      "|    explained_variance   | -0.0718    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0857    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0714    |\n",
      "|    value_loss           | 0.00111    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 337        |\n",
      "|    ep_rew_mean          | -0.131     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 227        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 126        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04990136 |\n",
      "|    clip_fraction        | 0.518      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.77      |\n",
      "|    explained_variance   | -0.0186    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0896    |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.079     |\n",
      "|    value_loss           | 0.000582   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | -0.124      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 227         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052302193 |\n",
      "|    clip_fraction        | 0.519       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | -0.113      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0657     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0776     |\n",
      "|    value_loss           | 0.00056     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 340        |\n",
      "|    ep_rew_mean          | -0.125     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 227        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06879389 |\n",
      "|    clip_fraction        | 0.658      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.67      |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.153     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.122     |\n",
      "|    value_loss           | 7.73e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053891115 |\n",
      "|    clip_fraction        | 0.508       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | -0.109      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0986     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0715     |\n",
      "|    value_loss           | 0.0005      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | -0.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054172106 |\n",
      "|    clip_fraction        | 0.519       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | -0.00526    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.043      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0701     |\n",
      "|    value_loss           | 0.000741    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055029843 |\n",
      "|    clip_fraction        | 0.549       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.000707    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.12       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.069      |\n",
      "|    value_loss           | 0.000582    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 343        |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06600511 |\n",
      "|    clip_fraction        | 0.645      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.61      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.15      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.121     |\n",
      "|    value_loss           | 3.67e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066694334 |\n",
      "|    clip_fraction        | 0.598       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.128      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.111      |\n",
      "|    value_loss           | 2.65e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 339        |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 228        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06929804 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.6       |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.154     |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.121     |\n",
      "|    value_loss           | 1.7e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.069599055 |\n",
      "|    clip_fraction        | 0.636       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.136      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.119      |\n",
      "|    value_loss           | 1.2e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 340        |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 214        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04980069 |\n",
      "|    clip_fraction        | 0.474      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.55      |\n",
      "|    explained_variance   | -0.0153    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0462    |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0545    |\n",
      "|    value_loss           | 0.00107    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 342        |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 229        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04710079 |\n",
      "|    clip_fraction        | 0.487      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.71      |\n",
      "|    explained_variance   | -0.0345    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0665    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.063     |\n",
      "|    value_loss           | 0.00117    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058248624 |\n",
      "|    clip_fraction        | 0.53        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | -0.0375     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0671     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0741     |\n",
      "|    value_loss           | 0.000624    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 350        |\n",
      "|    ep_rew_mean          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07070025 |\n",
      "|    clip_fraction        | 0.624      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.46      |\n",
      "|    explained_variance   | -0.254     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.128     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.116     |\n",
      "|    value_loss           | 4.17e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 353        |\n",
      "|    ep_rew_mean          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 249        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07241915 |\n",
      "|    clip_fraction        | 0.64       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.57      |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.138     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.117     |\n",
      "|    value_loss           | 3.05e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 356        |\n",
      "|    ep_rew_mean          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 230        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07717697 |\n",
      "|    clip_fraction        | 0.665      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.59      |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.153     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.121     |\n",
      "|    value_loss           | 1.98e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 230         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054188155 |\n",
      "|    clip_fraction        | 0.49        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0867     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0557     |\n",
      "|    value_loss           | 0.000641    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050380267 |\n",
      "|    clip_fraction        | 0.525       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.0262      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.082      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0628     |\n",
      "|    value_loss           | 0.00162     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 352       |\n",
      "|    ep_rew_mean          | -0.13     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 231       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 283       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0675894 |\n",
      "|    clip_fraction        | 0.554     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.58     |\n",
      "|    explained_variance   | -0.0399   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.114    |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -0.0764   |\n",
      "|    value_loss           | 0.000452  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | -0.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068302944 |\n",
      "|    clip_fraction        | 0.549       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.113      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0753     |\n",
      "|    value_loss           | 0.000402    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 231         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060057007 |\n",
      "|    clip_fraction        | 0.481       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0611     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0616     |\n",
      "|    value_loss           | 0.000703    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 344        |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 231        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08361319 |\n",
      "|    clip_fraction        | 0.664      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.49      |\n",
      "|    explained_variance   | 0.377      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.137     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.123     |\n",
      "|    value_loss           | 5.71e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.077725574 |\n",
      "|    clip_fraction        | 0.652       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.128      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.113      |\n",
      "|    value_loss           | 5.56e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053727448 |\n",
      "|    clip_fraction        | 0.507       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.0194      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.105      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0628     |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | -0.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058766812 |\n",
      "|    clip_fraction        | 0.496       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.5        |\n",
      "|    explained_variance   | 0.0225      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0603     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0623     |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | -0.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 232         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071693845 |\n",
      "|    clip_fraction        | 0.576       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0715     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0817     |\n",
      "|    value_loss           | 0.000361    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 331        |\n",
      "|    ep_rew_mean          | -0.19      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 351        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05680071 |\n",
      "|    clip_fraction        | 0.485      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.46      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0525    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    value_loss           | 0.000912   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 335        |\n",
      "|    ep_rew_mean          | -0.17      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 360        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07008179 |\n",
      "|    clip_fraction        | 0.553      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.39      |\n",
      "|    explained_variance   | -0.0649    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.131     |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0774    |\n",
      "|    value_loss           | 0.000658   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 332        |\n",
      "|    ep_rew_mean          | -0.18      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 368        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09399994 |\n",
      "|    clip_fraction        | 0.667      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.53      |\n",
      "|    explained_variance   | -0.005     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.136     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.119     |\n",
      "|    value_loss           | 6.47e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 334       |\n",
      "|    ep_rew_mean          | -0.19     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 233       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 377       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0670933 |\n",
      "|    clip_fraction        | 0.541     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.44     |\n",
      "|    explained_variance   | 0.0163    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0457   |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.0643   |\n",
      "|    value_loss           | 0.00062   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | -0.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059864983 |\n",
      "|    clip_fraction        | 0.483       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | -0.0219     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.129      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0616     |\n",
      "|    value_loss           | 0.000733    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | -0.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.079356894 |\n",
      "|    clip_fraction        | 0.628       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.44       |\n",
      "|    explained_variance   | -0.325      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.13       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.11       |\n",
      "|    value_loss           | 6.59e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 329        |\n",
      "|    ep_rew_mean          | -0.18      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 233        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 402        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08194585 |\n",
      "|    clip_fraction        | 0.633      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.46      |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.118     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.107     |\n",
      "|    value_loss           | 4.41e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | -0.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056090504 |\n",
      "|    clip_fraction        | 0.55        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0912     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.062      |\n",
      "|    value_loss           | 0.00179     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 325        |\n",
      "|    ep_rew_mean          | -0.18      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 419        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07693404 |\n",
      "|    clip_fraction        | 0.567      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.4       |\n",
      "|    explained_variance   | -0.00442   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.063     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0801    |\n",
      "|    value_loss           | 0.000465   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 324        |\n",
      "|    ep_rew_mean          | -0.16      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 234        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 427        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07719641 |\n",
      "|    clip_fraction        | 0.611      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.48      |\n",
      "|    explained_variance   | 0.0309     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0602    |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0866    |\n",
      "|    value_loss           | 0.000612   |\n",
      "----------------------------------------\n",
      "Model has been saved.\n",
      "Finished training on chess_v6.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation/training hyperparameter notes:\n",
    "# 10k steps: Winrate:  0.76, loss order of 1e-03\n",
    "# 20k steps: Winrate:  0.86, loss order of 1e-04\n",
    "# 40k steps: Winrate:  0.86, loss order of 7e-06\n",
    "train_action_mask(env_fn, steps=100_000, seed=0, **env_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation vs a random agent. Trained agent will play as player_1.\n",
      "Using policy connect_four_v3_20231102-200716.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/dev/ai-guild/.amog/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "/Users/luis/dev/ai-guild/.amog/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards by round:  [{'player_0': -1, 'player_1': 1}, {'player_0': 1, 'player_1': -1}]\n",
      "Total rewards (incl. negative rewards):  {'player_0': 0, 'player_1': 0}\n",
      "Winrate:  0.5\n",
      "Final scores:  {'player_0': 1, 'player_1': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'player_0': -1, 'player_1': 1}, {'player_0': 1, 'player_1': -1}],\n",
       " {'player_0': 0, 'player_1': 0},\n",
       " 0.5,\n",
       " {'player_0': 1, 'player_1': 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_action_mask(env_fn, num_games=2, render_mode=\"human\", **env_kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
