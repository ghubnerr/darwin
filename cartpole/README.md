Proximal Policy Optimization (PPO) on Discrete Action Space Environments
-

Untrained Preview
-

Trained Preview
-
https://github.com/ghubnerr/darwin/assets/91924667/1403a870-6fa2-45a8-bdf5-5746dd6f4f92

Observations
-
In the trained model, the agent was able to successfully maintain the balance of the sitck/pole with minimal angular discrepancies. 

Dependencies
-

Description
-
This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson in “Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem”. A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum is placed upright on the cart and the goal is to balance the pole by applying forces in the left and right direction on the cart.

This environment specifications and documentation can be found on Open AI Gym's website: 
https://gymnasium.farama.org/environments/classic_control/cart_pole/

Action Space
-

Rewards
-

